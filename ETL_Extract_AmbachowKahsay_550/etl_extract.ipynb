{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b7c75b21",
   "metadata": {},
   "source": [
    "# ETL Extract Lab - DSA 2040A"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73026fea",
   "metadata": {},
   "source": [
    "\n",
    "## Project Setup\n",
    " This notebook demonstrates:\n",
    "- Full dataset extraction\n",
    "- Incremental extraction based on last run timestamp\n",
    "- Proper ETL workflow practices\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "73922386",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import Required Libraries\n",
    "import pandas as pd\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8010bf75",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Section 1: Full Extraction\n",
    "\n",
    "def full_extraction(file_path):\n",
    "    \"\"\"Perform a full extraction of the dataset\"\"\"\n",
    "    try:\n",
    "        df = pd.read_csv(file_path)\n",
    "        print(\"Full extraction completed successfully.\")\n",
    "        print(f\"Extracted {len(df)} rows fully.\")\n",
    "        \n",
    "        # Display basic stats\n",
    "        print(\"\\nDataset Info:\")\n",
    "        print(df.info())\n",
    "        \n",
    "        print(\"\\nSample Data:\")\n",
    "        return df.head()\n",
    "    except Exception as e:\n",
    "        print(f\"Error during full extraction: {e}\")\n",
    "        return None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8b8a1c9d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during full extraction: [Errno 2] No such file or directory: 'custom_data.csv'\n"
     ]
    }
   ],
   "source": [
    "# Full extraction example\n",
    "file_path = \"custom_data.csv\"\n",
    "full_extraction(file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "35249efb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during incremental extraction: [Errno 2] No such file or directory: 'custom_data.csv'\n"
     ]
    }
   ],
   "source": [
    "# Incremental Extraction\n",
    "\n",
    "# %%\n",
    "def read_last_extraction_time():\n",
    "    \"\"\"Read the last extraction timestamp from file\"\"\"\n",
    "    try:\n",
    "        with open('last_extraction.txt', 'r') as f:\n",
    "            return datetime.strptime(f.read().strip(), '%Y-%m-%d %H:%M:%S')\n",
    "    except (FileNotFoundError, ValueError):\n",
    "        # Default to beginning of time if file doesn't exist\n",
    "        return datetime.min\n",
    "\n",
    "# %%\n",
    "def incremental_extraction(file_path):\n",
    "    \"\"\"Perform incremental extraction based on last run\"\"\"\n",
    "    try:\n",
    "        # Read the complete data\n",
    "        full_df = pd.read_csv(file_path)\n",
    "        \n",
    "        # Convert Date column to datetime\n",
    "        full_df['Date'] = pd.to_datetime(full_df['Date'])\n",
    "        \n",
    "        # Get last extraction time\n",
    "        last_time = read_last_extraction_time()\n",
    "        print(f\"Last extraction was at: {last_time}\")\n",
    "        \n",
    "        # Filter for new records\n",
    "        new_data = full_df[full_df['Date'] > last_time]\n",
    "        \n",
    "        print(f\"Extracted {len(new_data)} rows incrementally since last check.\")\n",
    "        return new_data\n",
    "    except Exception as e:\n",
    "        print(f\"Error during incremental extraction: {e}\")\n",
    "        return None\n",
    "\n",
    "# Example incremental extraction\n",
    "incremental_data = incremental_extraction(file_path)\n",
    "if incremental_data is not None and not incremental_data.empty:\n",
    "    print(\"\\nNew data since last extraction:\")\n",
    "    print(incremental_data)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "83ce942c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Updated last extraction time to: 2025-06-15 14:42:13\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Section 3: Save New Timestamp\n",
    "# %%\n",
    "def update_extraction_time():\n",
    "    \"\"\"Update the last extraction timestamp to current time\"\"\"\n",
    "    try:\n",
    "        current_time = datetime.now().strftime('%Y-%m-%d %H:%M:%S')\n",
    "        with open('last_extraction.txt', 'w') as f:\n",
    "            f.write(current_time)\n",
    "        print(f\"Updated last extraction time to: {current_time}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error updating extraction time: {e}\")\n",
    "\n",
    "# Update timestamp after successful incremental extraction\n",
    "update_extraction_time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8bd9420a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Updated last extraction time to: 2025-06-15 14:42:13\n"
     ]
    }
   ],
   "source": [
    "# Section 4: Update Extraction Timestamp\n",
    "\n",
    "def update_extraction_time():\n",
    "    \"\"\"Update the last extraction timestamp to current time\"\"\"\n",
    "    try:\n",
    "        current_time = datetime.now().strftime('%Y-%m-%d %H:%M:%S')\n",
    "        with open('last_extraction.txt', 'w') as f:\n",
    "            f.write(current_time)\n",
    "        print(f\"Updated last extraction time to: {current_time}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error updating extraction time: {e}\")\n",
    "\n",
    "update_extraction_time()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0c4feffe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Section 5. Transform Full Data\n",
    "\n",
    "def transform_data(df):\n",
    "    \"\"\"Apply transformations to the dataset\"\"\"\n",
    "    if df is None or df.empty:\n",
    "        print(\"No data to transform.\")\n",
    "        return df\n",
    "\n",
    "    # 1. Cleaning\n",
    "    df = df.drop_duplicates()\n",
    "    df.fillna({'Quantity': 0, 'Price per Unit': 0}, inplace=True)\n",
    "\n",
    "    # 2. Enrichment\n",
    "    df['Computed Total'] = df['Quantity'] * df['Price per Unit']\n",
    "\n",
    "    # 3. Structural\n",
    "    df['Date'] = pd.to_datetime(df['Date'])  # Standardize date\n",
    "    df['Age Group'] = pd.cut(df['Age'],\n",
    "                                bins=[0, 18, 35, 50, 100],\n",
    "                                labels=['Teen', 'Young Adult', 'Middle Aged', 'Senior'])\n",
    "\n",
    "    print(\"Transformation complete.\")\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb50ab78",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_full_transformed = transform_data(df_full)\n",
    "df_full_transformed.to_csv(\"transformed_full.csv\", index=False)\n",
    "print(\"Transformed full dataset saved to transformed_full.csv\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
