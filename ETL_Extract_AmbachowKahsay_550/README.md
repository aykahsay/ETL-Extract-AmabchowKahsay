# ğŸ“Š ETL Extract Lab

**Course**: DSA 2040A â€“ Data Warehousing and Mining
---

### ğŸ“˜ Description

This project demonstrates **Full Extraction**, **Incremental Extraction**, **Data Transformation**, and **Data Loading** as part of an ETL pipeline using a retail sales dataset. It's designed to help reinforce practical data engineering concepts across ETL stages.

---

### ğŸ”§ Tools Used

* Python
* pandas
* Jupyter Notebook
* SQLite
* Parquet (optional)

---

### ğŸ“ Project Folder Structure

```
ETL_Extract_AmbachowKahsay_550/
â”œâ”€â”€ custom_data.csv                # Raw dataset
â”œâ”€â”€ etl_extract.ipynb             # Full & Incremental Extraction
â”œâ”€â”€ etl_load.ipynb                # Data Loading (Lab 5)
â”œâ”€â”€ transformed_full.csv          # Transformed full dataset
â”œâ”€â”€ transformed_incremental.csv   # Transformed incremental dataset
â”œâ”€â”€ last_extraction.txt           # Timestamp for incremental logic
â”œâ”€â”€ .gitignore                    # Files to exclude in GitHub
â”œâ”€â”€ README.md                     # Project documentation
â””â”€â”€ loaded_data/
    â”œâ”€â”€ full_data.db              # Full dataset in SQLite
    â”œâ”€â”€ incremental_data.db       # Incremental dataset in SQLite
```

---

## ğŸ” Dataset

* **Name**: Retail Sales Dataset
* **Source**: [Kaggle â€“ Mohammad Talib786](https://www.kaggle.com/datasets/mohammadtalib786/retail-sales-dataset)
* **Description**: Contains simulated retail transactions including fields like `Transaction ID`, `Date`, `Customer ID`, `Gender`, `Age`, `Product Category`, `Quantity`,and  `Price per Unit`.

---

## ğŸ”„ Lab 3 â€“ Extraction

* **Full Extraction**: Loads the entire dataset and prints structure + summary.
* **Incremental Extraction**: Extracts only records newer than the timestamp saved in `last_extraction.txt`.
* **Timestamp Update**: Automatically updates after successful incremental extraction.

ï¸âœ… Output: Preview of data, extraction logs, and filtered results.

---

## ğŸ” Lab 4 â€“ Transformation

Applied **3+ transformations** on both full and incremental data:

### âœ… Cleaning

* Removed duplicate rows
* Handled missing and inconsistent values
* Standardized column formats

### âœ… Enrichment

* Added `Total Amount = Quantity Ã— Price per Unit`
* Categorized `Age` into groups (e.g., 18â€“25, 26â€“35, etc.)

### âœ… Structural

* Converted `Date` column to datetime format
* Renamed or formatted columns for clarity

ï¸âœ… Output:

* `transformed_full.csv`
* `transformed_incremental.csv`

---

## ğŸ“‚ Lab 5 â€“ Load

Data was loaded into structured formats:

### âœ… SQLite

* Full data â†’ `loaded_data/full_data.db`
* Incremental data â†’ `loaded_data/incremental_data.db`

### âœ… Example Schema

```sql
CREATE TABLE data (
    Transaction_ID INTEGER,
    Date TEXT,
    Customer_ID TEXT,
    Gender TEXT,
    Age INTEGER,
    Product_Category TEXT,
    Quantity INTEGER,
    Price_per_Unit REAL,
    Total_Amount REAL
);
```

---

## â–¶ï¸ How to Run

1. Install requirements:

   ```bash
   pip install pandas
   ```

2. Run extraction:

   ```bash
   jupyter notebook etl_extract.ipynb
   ```

3. Run loading:

   ```bash
   jupyter notebook etl_load.ipynb
   ```

---

## ğŸ“† .gitignore Example

```
.ipynb_checkpoints/
__pycache__/
*.log
*.db
*.parquet
last_extraction.txt
loaded_data/
```

---
